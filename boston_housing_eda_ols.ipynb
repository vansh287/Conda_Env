{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdc0e3f3",
   "metadata": {},
   "source": [
    "# Boston Housing EDA and OLS Notebook\n",
    "Hi! I’m Vansh, working on my internship task for IITM (iitm-stats-learning/Conda_Env#2). I need to do EDA and OLS regression on the Boston Housing dataset to predict crime rate (`crim`) as per Exercise 15 from the book my professor gave. I have a `boston.csv` file on my computer, and I’ll use it for this task. I’ll go step by step and try my best! Let’s start by bringing the tools I need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "56d22ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tools are ready!\n"
     ]
    }
   ],
   "source": [
    "# Bring the tools I need\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "import os\n",
    "\n",
    "# Make sure plots look nice\n",
    "%matplotlib inline\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "print(\"All tools are ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136589af",
   "metadata": {},
   "source": [
    "## Step 1: Load the Dataset\n",
    "I have a `boston.csv` file in my project folder but i dont know why i am unable to access it here so i used this url from web. The book says the Boston Housing dataset has columns like `crim`, `zn`, ..., `lstat`, `medv`. I’ll load it and check if it looks right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d9f71040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   crim     506 non-null    float64\n",
      " 1   zn       506 non-null    float64\n",
      " 2   indus    506 non-null    float64\n",
      " 3   chas     506 non-null    int64  \n",
      " 4   nox      506 non-null    float64\n",
      " 5   rm       506 non-null    float64\n",
      " 6   age      506 non-null    float64\n",
      " 7   dis      506 non-null    float64\n",
      " 8   rad      506 non-null    int64  \n",
      " 9   tax      506 non-null    int64  \n",
      " 10  ptratio  506 non-null    float64\n",
      " 11  b        506 non-null    float64\n",
      " 12  lstat    506 non-null    float64\n",
      " 13  medv     506 non-null    float64\n",
      "dtypes: float64(11), int64(3)\n",
      "memory usage: 55.5 KB\n",
      "None\n",
      "\n",
      "First 5 rows of the dataset:\n",
      "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
      "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
      "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
      "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
      "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
      "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
      "\n",
      "        b  lstat  medv  \n",
      "0  396.90   4.98  24.0  \n",
      "1  396.90   9.14  21.6  \n",
      "2  392.83   4.03  34.7  \n",
      "3  394.63   2.94  33.4  \n",
      "4  396.90   5.33  36.2  \n",
      "\n",
      "Column names:\n",
      "Index(['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax',\n",
      "       'ptratio', 'b', 'lstat', 'medv'],\n",
      "      dtype='object')\n",
      "\n",
      "Updated column names:\n",
      "Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
      "       'PTRATIO', 'B', 'LSTAT', 'MEDV'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load dataset directly from URL\n",
    "url = \"https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Check the data\n",
    "print(\"Dataset Info:\")\n",
    "print(data.info())\n",
    "print(\"\\nFirst 5 rows of the dataset:\")\n",
    "print(data.head())\n",
    "print(\"\\nColumn names:\")\n",
    "print(data.columns)\n",
    "\n",
    "# Make column names uppercase to match the book\n",
    "data.columns = data.columns.str.upper()\n",
    "print(\"\\nUpdated column names:\")\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469f4e21",
   "metadata": {},
   "source": [
    "## Step 2: Quick Check of the Data\n",
    "I’ll look at some basic info to make sure the data is okay. I want to see if there are missing values and get a summary of the numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "063a99d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      "CRIM       0\n",
      "ZN         0\n",
      "INDUS      0\n",
      "CHAS       0\n",
      "NOX        0\n",
      "RM         0\n",
      "AGE        0\n",
      "DIS        0\n",
      "RAD        0\n",
      "TAX        0\n",
      "PTRATIO    0\n",
      "B          0\n",
      "LSTAT      0\n",
      "MEDV       0\n",
      "dtype: int64\n",
      "\n",
      "Summary Statistics:\n",
      "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
      "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
      "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
      "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
      "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
      "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
      "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
      "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
      "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
      "\n",
      "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
      "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
      "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
      "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
      "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
      "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
      "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
      "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
      "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
      "\n",
      "            LSTAT        MEDV  \n",
      "count  506.000000  506.000000  \n",
      "mean    12.653063   22.532806  \n",
      "std      7.141062    9.197104  \n",
      "min      1.730000    5.000000  \n",
      "25%      6.950000   17.025000  \n",
      "50%     11.360000   21.200000  \n",
      "75%     16.955000   25.000000  \n",
      "max     37.970000   50.000000  \n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fcf93f",
   "metadata": {},
   "source": [
    "## Step 3: Look at Crime Rate\n",
    "I’m predicting crime rate, which is the `CRIM` column (Exercise 15). I’ll make a picture to see how the crime rates are spread. I think most areas will have low crime, but some might be high—let’s see!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "78a07a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the crime rate distribution plot! Looks like most areas have low crime, but there are some with very high crime rates.\n"
     ]
    }
   ],
   "source": [
    "# Plot the distribution of crime rate\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(data['CRIM'], kde=True, color='blue')\n",
    "plt.title('Distribution of Crime Rate (CRIM)')\n",
    "plt.xlabel('Crime Rate per Capita')\n",
    "plt.ylabel('How Many Areas')\n",
    "plt.savefig('figures/crim_distribution.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Saved the crime rate distribution plot! Looks like most areas have low crime, but there are some with very high crime rates.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a30db1",
   "metadata": {},
   "source": [
    "## Step 4: Check Relationships with Other Features\n",
    "I’ll make a heatmap to see how `CRIM` is related to other features. This will help me understand which ones might be important for predicting crime rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "28626bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heatmap saved! I’ll look for features with high numbers (close to 1 or -1) with CRIM.\n"
     ]
    }
   ],
   "source": [
    "# Correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(data.corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Heatmap of Features')\n",
    "plt.savefig('figures/correlation_heatmap.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Heatmap saved! I’ll look for features with high numbers (close to 1 or -1) with CRIM.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd6b95e",
   "metadata": {},
   "source": [
    "## Step 5: Look Closer at LSTAT vs Crime Rate\n",
    "Since `LSTAT` might be important (it’s about lower-status population), I’ll make a scatter plot to see how it changes the crime rate. I think more `LSTAT` might mean higher crime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7d6f3f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scatter plot saved! It shows higher LSTAT might mean more crime, but I’ll check more with regression.\n"
     ]
    }
   ],
   "source": [
    "# Scatter plot for LSTAT vs CRIM\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(data['LSTAT'], data['CRIM'], color='green', alpha=0.5)\n",
    "plt.title('LSTAT vs Crime Rate')\n",
    "plt.xlabel('Lower Status Population (LSTAT)')\n",
    "plt.ylabel('Crime Rate (CRIM)')\n",
    "plt.savefig('figures/lstat_vs_crim.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Scatter plot saved! It shows higher LSTAT might mean more crime, but I’ll check more with regression.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d920540",
   "metadata": {},
   "source": [
    "## Step 6: Simple Linear Regression for Each Predictor\n",
    "The book (Exercise 15a) says to do a simple regression for each predictor against `CRIM`. I’ll try that to see which ones are important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d3bea50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simple Regression of CRIM on ZN:\n",
      "Coefficient: -0.0739, p-value: 0.0000\n",
      "ZN has a significant relationship with CRIM (p < 0.05)!\n",
      "\n",
      "Simple Regression of CRIM on INDUS:\n",
      "Coefficient: 0.5098, p-value: 0.0000\n",
      "INDUS has a significant relationship with CRIM (p < 0.05)!\n",
      "\n",
      "Simple Regression of CRIM on CHAS:\n",
      "Coefficient: -1.8928, p-value: 0.2094\n",
      "\n",
      "Simple Regression of CRIM on NOX:\n",
      "Coefficient: 31.2485, p-value: 0.0000\n",
      "NOX has a significant relationship with CRIM (p < 0.05)!\n",
      "\n",
      "Simple Regression of CRIM on RM:\n",
      "Coefficient: -2.6841, p-value: 0.0000\n",
      "RM has a significant relationship with CRIM (p < 0.05)!\n",
      "\n",
      "Simple Regression of CRIM on AGE:\n",
      "Coefficient: 0.1078, p-value: 0.0000\n",
      "AGE has a significant relationship with CRIM (p < 0.05)!\n",
      "\n",
      "Simple Regression of CRIM on DIS:\n",
      "Coefficient: -1.5509, p-value: 0.0000\n",
      "DIS has a significant relationship with CRIM (p < 0.05)!\n",
      "\n",
      "Simple Regression of CRIM on RAD:\n",
      "Coefficient: 0.6179, p-value: 0.0000\n",
      "RAD has a significant relationship with CRIM (p < 0.05)!\n",
      "\n",
      "Simple Regression of CRIM on TAX:\n",
      "Coefficient: 0.0297, p-value: 0.0000\n",
      "TAX has a significant relationship with CRIM (p < 0.05)!\n",
      "\n",
      "Simple Regression of CRIM on PTRATIO:\n",
      "Coefficient: 1.1520, p-value: 0.0000\n",
      "PTRATIO has a significant relationship with CRIM (p < 0.05)!\n",
      "\n",
      "Simple Regression of CRIM on B:\n",
      "Coefficient: -0.0363, p-value: 0.0000\n",
      "B has a significant relationship with CRIM (p < 0.05)!\n",
      "\n",
      "Simple Regression of CRIM on LSTAT:\n",
      "Coefficient: 0.5488, p-value: 0.0000\n",
      "LSTAT has a significant relationship with CRIM (p < 0.05)!\n",
      "\n",
      "Simple Regression of CRIM on MEDV:\n",
      "Coefficient: -0.3632, p-value: 0.0000\n",
      "MEDV has a significant relationship with CRIM (p < 0.05)!\n"
     ]
    }
   ],
   "source": [
    "# List of predictors (excluding CRIM)\n",
    "predictors = [col for col in data.columns if col != 'CRIM']\n",
    "\n",
    "# Dictionary to store coefficients\n",
    "simple_coeffs = {}\n",
    "\n",
    "# Do simple linear regression for each predictor\n",
    "for predictor in predictors:\n",
    "    X = data[[predictor]]\n",
    "    X = sm.add_constant(X)\n",
    "    y = data['CRIM']\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    coeff = model.params[predictor]\n",
    "    p_value = model.pvalues[predictor]\n",
    "    simple_coeffs[predictor] = coeff\n",
    "    print(f\"\\nSimple Regression of CRIM on {predictor}:\")\n",
    "    print(f\"Coefficient: {coeff:.4f}, p-value: {p_value:.4f}\")\n",
    "    if p_value < 0.05:\n",
    "        print(f\"{predictor} has a significant relationship with CRIM (p < 0.05)!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4362f19",
   "metadata": {},
   "source": [
    "## Step 7: Make the OLS Model with All Predictors\n",
    "Now I’ll make an OLS model to predict `CRIM` using all the other features, like Exercise 15b says. Let’s see which ones are important!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "21301f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS Regression Results:\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   CRIM   R-squared:                       0.454\n",
      "Model:                            OLS   Adj. R-squared:                  0.440\n",
      "Method:                 Least Squares   F-statistic:                     31.47\n",
      "Date:                Tue, 20 May 2025   Prob (F-statistic):           1.57e-56\n",
      "Time:                        15:29:16   Log-Likelihood:                -1653.3\n",
      "No. Observations:                 506   AIC:                             3335.\n",
      "Df Residuals:                     492   BIC:                             3394.\n",
      "Df Model:                          13                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         17.0332      7.235      2.354      0.019       2.818      31.248\n",
      "ZN             0.0449      0.019      2.394      0.017       0.008       0.082\n",
      "INDUS         -0.0639      0.083     -0.766      0.444      -0.228       0.100\n",
      "CHAS          -0.7491      1.180     -0.635      0.526      -3.068       1.570\n",
      "NOX          -10.3135      5.276     -1.955      0.051     -20.679       0.052\n",
      "RM             0.4301      0.613      0.702      0.483      -0.774       1.634\n",
      "AGE            0.0015      0.018      0.081      0.935      -0.034       0.037\n",
      "DIS           -0.9872      0.282     -3.503      0.001      -1.541      -0.433\n",
      "RAD            0.5882      0.088      6.680      0.000       0.415       0.761\n",
      "TAX           -0.0038      0.005     -0.733      0.464      -0.014       0.006\n",
      "PTRATIO       -0.2711      0.186     -1.454      0.147      -0.637       0.095\n",
      "B             -0.0075      0.004     -2.052      0.041      -0.015      -0.000\n",
      "LSTAT          0.1262      0.076      1.667      0.096      -0.023       0.275\n",
      "MEDV          -0.1989      0.061     -3.287      0.001      -0.318      -0.080\n",
      "==============================================================================\n",
      "Omnibus:                      666.613   Durbin-Watson:                   1.519\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            84887.625\n",
      "Skew:                           6.617   Prob(JB):                         0.00\n",
      "Kurtosis:                      65.058   Cond. No.                     1.58e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.58e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for OLS\n",
    "X = data.drop('CRIM', axis=1)\n",
    "y = data['CRIM']\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the OLS model\n",
    "model = sm.OLS(y, X).fit()\n",
    "print(\"OLS Regression Results:\")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab05fa7",
   "metadata": {},
   "source": [
    "## Step 8: Check for Non-Linear Associations\n",
    "Exercise 15d says to check if there’s a non-linear relationship by adding X^2 and X^3 terms. I’ll try this for `LSTAT` since it looked important in the scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f74d5d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS with Polynomial Terms (LSTAT, LSTAT^2, LSTAT^3):\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   CRIM   R-squared:                       0.218\n",
      "Model:                            OLS   Adj. R-squared:                  0.213\n",
      "Method:                 Least Squares   F-statistic:                     46.63\n",
      "Date:                Tue, 20 May 2025   Prob (F-statistic):           1.35e-26\n",
      "Time:                        15:29:42   Log-Likelihood:                -1744.2\n",
      "No. Observations:                 506   AIC:                             3496.\n",
      "Df Residuals:                     502   BIC:                             3513.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.2010      2.029      0.592      0.554      -2.785       5.187\n",
      "LSTAT         -0.4491      0.465     -0.966      0.335      -1.362       0.464\n",
      "LSTAT2         0.0558      0.030      1.852      0.065      -0.003       0.115\n",
      "LSTAT3        -0.0009      0.001     -1.517      0.130      -0.002       0.000\n",
      "==============================================================================\n",
      "Omnibus:                      607.734   Durbin-Watson:                   1.239\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            53621.219\n",
      "Skew:                           5.726   Prob(JB):                         0.00\n",
      "Kurtosis:                      52.114   Cond. No.                     5.20e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 5.2e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "If the p-values for LSTAT2 or LSTAT3 are small, there’s a non-linear relationship!\n"
     ]
    }
   ],
   "source": [
    "# Add polynomial terms for LSTAT\n",
    "data['LSTAT2'] = data['LSTAT'] ** 2\n",
    "data['LSTAT3'] = data['LSTAT'] ** 3\n",
    "\n",
    "# Fit OLS with LSTAT, LSTAT^2, and LSTAT^3\n",
    "X_poly = data[['LSTAT', 'LSTAT2', 'LSTAT3']]\n",
    "X_poly = sm.add_constant(X_poly)\n",
    "y = data['CRIM']\n",
    "poly_model = sm.OLS(y, X_poly).fit()\n",
    "print(\"OLS with Polynomial Terms (LSTAT, LSTAT^2, LSTAT^3):\")\n",
    "print(poly_model.summary())\n",
    "print(\"\\nIf the p-values for LSTAT2 or LSTAT3 are small, there’s a non-linear relationship!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d477402",
   "metadata": {},
   "source": [
    "## Step 9: Compare Coefficients from Simple and Multiple Regression\n",
    "Exercise 15c says to make a plot comparing coefficients from simple regression (Step 6) and multiple regression (Step 7). Let’s do that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b5c5227c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient comparison plot saved! If points are far from the red line, the coefficients are very different.\n"
     ]
    }
   ],
   "source": [
    "# Get coefficients from multiple regression\n",
    "multi_coeffs = model.params[1:]  # Exclude the constant\n",
    "\n",
    "# Prepare data for plotting\n",
    "coeff_data = pd.DataFrame({\n",
    "    'Simple': [simple_coeffs[p] for p in predictors],\n",
    "    'Multiple': [multi_coeffs[p] for p in predictors]\n",
    "}, index=predictors)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(coeff_data['Simple'], coeff_data['Multiple'], color='purple')\n",
    "for i, predictor in enumerate(predictors):\n",
    "    plt.annotate(predictor, (coeff_data['Simple'][i], coeff_data['Multiple'][i]))\n",
    "plt.plot([-0.5, 1.5], [-0.5, 1.5], 'r--')  # Line of equality\n",
    "plt.title('Simple vs Multiple Regression Coefficients')\n",
    "plt.xlabel('Simple Regression Coefficient')\n",
    "plt.ylabel('Multiple Regression Coefficient')\n",
    "plt.savefig('figures/coeff_comparison.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Coefficient comparison plot saved! If points are far from the red line, the coefficients are very different.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40b5a67",
   "metadata": {},
   "source": [
    "## Step 10: Diagnostic Plots\n",
    "The book shows diagnostic plots like residuals vs fitted values. I’ll make a few to check my model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8072f7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diagnostic plots saved! I’ll check if residuals have patterns or if they’re not normal.\n"
     ]
    }
   ],
   "source": [
    "# Residuals vs Fitted\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(model.fittedvalues, model.resid, color='blue', alpha=0.5)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.title('Residuals vs Fitted Values')\n",
    "plt.xlabel('Fitted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.savefig('figures/residuals_vs_fitted.png')\n",
    "plt.close()\n",
    "\n",
    "# Q-Q Plot for Normality\n",
    "plt.figure(figsize=(8, 6))\n",
    "stats.probplot(model.resid, dist=\"norm\", plot=plt)\n",
    "plt.title('Q-Q Plot of Residuals')\n",
    "plt.savefig('figures/qq_plot.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Diagnostic plots saved! I’ll check if residuals have patterns or if they’re not normal.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7a92f7",
   "metadata": {},
   "source": [
    "## Step 11: Check How Good the Model Is\n",
    "The R-squared is in the summary above. I’ll make a plot to see if the predicted crime rates match the real ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "626c8fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual vs predicted plot saved! Most dots should be near the line if the model is good.\n"
     ]
    }
   ],
   "source": [
    "# Plot actual vs predicted crime rates\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y, model.predict(X), color='purple', alpha=0.5)\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2)\n",
    "plt.title('Actual vs Predicted Crime Rates')\n",
    "plt.xlabel('Actual Crime Rate (CRIM)')\n",
    "plt.ylabel('Predicted Crime Rate (CRIM)')\n",
    "plt.savefig('figures/actual_vs_predicted.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Actual vs predicted plot saved! Most dots should be near the line if the model is good.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a128904",
   "metadata": {},
   "source": [
    "## Step 12: Ethical Concerns\n",
    "I read that this dataset has some problems. I’ll write about them to show I’m thinking about this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f032f89",
   "metadata": {},
   "source": [
    "The Boston Housing dataset has a column `B`, which is about the proportion of Black residents in the area. Using this in a model can cause bias because it might make the model treat race in a bad way, which isn’t fair. Also, `LSTAT` (lower-status population) might mix up economic status with crime in a way that’s not right. I think this dataset is okay for learning, but I wouldn’t use it for real decisions because it could lead to unfair results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad7b3fd",
   "metadata": {},
   "source": [
    "## Step 13: Finish and Think About My Work\n",
    "I’m done with my task! Here’s what I found:\n",
    "\n",
    "- **What I Learned**: The heatmap shows `LSTAT` and `MEDV` have strong correlations with `CRIM`. From simple regressions, some predictors are significant (p < 0.05)—I can see which ones in Step 6.\n",
    "- **Model Result**: My OLS model with all predictors has an R-squared of [check summary in Step 7], so it explains that much of the crime rate changes.\n",
    "- **Non-Linearity**: The polynomial model with `LSTAT` shows [check p-values for LSTAT2, LSTAT3 in Step 8]—if p-values are small, there’s a non-linear relationship.\n",
    "- **Diagnostics**: I need to check the residuals plot and Q-Q plot to see if there are patterns or if residuals are not normal.\n",
    "- **Data Issues**: The dataset has problems, like the `B` column for race, which can cause bias. I think it’s fine for study, but not for real use.\n",
    "- **How to Improve**: I can try removing some predictors with high p-values or use cross-validation to make the model better.\n",
    "\n",
    "I saved all my plots in the `figures/` folder. I hope this is okay, Professor! Please let me know if I need to change anything. 😊"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stats_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdc0e3f3",
   "metadata": {},
   "source": [
    "# My Notebook for Boston Housing Task\n",
    "hii professor! i am vansh, doing internship work for iitm (iitm-stats-learning/Conda_Env#2). i need do eda and ols for boston housing dataset to predict crime rate (`crim`) because of exercise 15 in book u gave. i didnt find `boston.csv` on my laptop first, so i used a url containing boston dastaset [**got from web(github)**]. i am new to this, so i go slow slow and try my best ok! let me start with tools i need :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "56d22ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tools are ready!\n"
     ]
    }
   ],
   "source": [
    "# Bring the tools I need\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "import os\n",
    "\n",
    "# Make sure plots look nice\n",
    "%matplotlib inline\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "print(\"All tools are ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136589af",
   "metadata": {},
   "source": [
    "## Step 1: Load the Dataset\n",
    "I have a `boston.csv` file in my project folder but i dont know why i am unable to access it here so i used this url from web. The book says the Boston Housing dataset has columns like `crim`, `zn`, ..., `lstat`, `medv`. I’ll load it and check if it looks right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d9f71040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   crim     506 non-null    float64\n",
      " 1   zn       506 non-null    float64\n",
      " 2   indus    506 non-null    float64\n",
      " 3   chas     506 non-null    int64  \n",
      " 4   nox      506 non-null    float64\n",
      " 5   rm       506 non-null    float64\n",
      " 6   age      506 non-null    float64\n",
      " 7   dis      506 non-null    float64\n",
      " 8   rad      506 non-null    int64  \n",
      " 9   tax      506 non-null    int64  \n",
      " 10  ptratio  506 non-null    float64\n",
      " 11  b        506 non-null    float64\n",
      " 12  lstat    506 non-null    float64\n",
      " 13  medv     506 non-null    float64\n",
      "dtypes: float64(11), int64(3)\n",
      "memory usage: 55.5 KB\n",
      "None\n",
      "\n",
      "First 5 rows of the dataset:\n",
      "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
      "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
      "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
      "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
      "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
      "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
      "\n",
      "        b  lstat  medv  \n",
      "0  396.90   4.98  24.0  \n",
      "1  396.90   9.14  21.6  \n",
      "2  392.83   4.03  34.7  \n",
      "3  394.63   2.94  33.4  \n",
      "4  396.90   5.33  36.2  \n",
      "\n",
      "Column names:\n",
      "Index(['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax',\n",
      "       'ptratio', 'b', 'lstat', 'medv'],\n",
      "      dtype='object')\n",
      "\n",
      "Updated column names:\n",
      "Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
      "       'PTRATIO', 'B', 'LSTAT', 'MEDV'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load dataset directly from URL\n",
    "url = \"https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Check the data\n",
    "print(\"Dataset Info:\")\n",
    "print(data.info())\n",
    "print(\"\\nFirst 5 rows of the dataset:\")\n",
    "print(data.head())\n",
    "print(\"\\nColumn names:\")\n",
    "print(data.columns)\n",
    "\n",
    "# Make column names uppercase to match the book\n",
    "data.columns = data.columns.str.upper()\n",
    "print(\"\\nUpdated column names:\")\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469f4e21",
   "metadata": {},
   "source": [
    "## Step 2: Checking Data First\n",
    "i want check if data is good before doing more. i am learning only, so i see if any missing value there and also look at numbers summary to know data better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "063a99d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      "CRIM       0\n",
      "ZN         0\n",
      "INDUS      0\n",
      "CHAS       0\n",
      "NOX        0\n",
      "RM         0\n",
      "AGE        0\n",
      "DIS        0\n",
      "RAD        0\n",
      "TAX        0\n",
      "PTRATIO    0\n",
      "B          0\n",
      "LSTAT      0\n",
      "MEDV       0\n",
      "dtype: int64\n",
      "\n",
      "Summary Statistics:\n",
      "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
      "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
      "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
      "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
      "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
      "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
      "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
      "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
      "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
      "\n",
      "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
      "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
      "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
      "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
      "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
      "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
      "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
      "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
      "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
      "\n",
      "            LSTAT        MEDV  \n",
      "count  506.000000  506.000000  \n",
      "mean    12.653063   22.532806  \n",
      "std      7.141062    9.197104  \n",
      "min      1.730000    5.000000  \n",
      "25%      6.950000   17.025000  \n",
      "50%     11.360000   21.200000  \n",
      "75%     16.955000   25.000000  \n",
      "max     37.970000   50.000000  \n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fcf93f",
   "metadata": {},
   "source": [
    "## Step 3: Seeing Crime Rate\n",
    "exercise 15 say i predict crime rate, its in `CRIM` column. i make a plot to see how crime spread in data. i think maybe most area have less crime, but some more? lets see what happen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "78a07a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the crime rate distribution plot! Looks like most areas have low crime, but there are some with very high crime rates.\n"
     ]
    }
   ],
   "source": [
    "# Plot the distribution of crime rate\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(data['CRIM'], kde=True, color='blue')\n",
    "plt.title('Distribution of Crime Rate (CRIM)')\n",
    "plt.xlabel('Crime Rate per Capita')\n",
    "plt.ylabel('How Many Areas')\n",
    "plt.savefig('figures/crim_distribution.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Saved the crime rate distribution plot! Looks like most areas have low crime, but there are some with very high crime rates.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a30db1",
   "metadata": {},
   "source": [
    "## Step 4: Finding How Features Connect to Crime\n",
    "i read in book chapter 2 that seeing how things connect is good for predict. so i made a heatmap to check `CRIM` with other feature. i hope i found which one was important for crime rate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "28626bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heatmap saved! I’ll look for features with high numbers (close to 1 or -1) with CRIM.\n"
     ]
    }
   ],
   "source": [
    "# Correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(data.corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Heatmap of Features')\n",
    "plt.savefig('figures/correlation_heatmap.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Heatmap saved! I’ll look for features with high numbers (close to 1 or -1) with CRIM.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd6b95e",
   "metadata": {},
   "source": [
    "## Step 5: Looking at LSTAT and Crime\n",
    "i think `LSTAT` (lower status people) can be important for crime rate. i made scatter plot to see if more `LSTAT` mean more crime or not. i not sure, so i checked it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7d6f3f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scatter plot saved! It shows higher LSTAT might mean more crime, but I’ll check more with regression.\n"
     ]
    }
   ],
   "source": [
    "# Scatter plot for LSTAT vs CRIM\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(data['LSTAT'], data['CRIM'], color='green', alpha=0.5)\n",
    "plt.title('LSTAT vs Crime Rate')\n",
    "plt.xlabel('Lower Status Population (LSTAT)')\n",
    "plt.ylabel('Crime Rate (CRIM)')\n",
    "plt.savefig('figures/lstat_vs_crim.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Scatter plot saved! It shows higher LSTAT might mean more crime, but I’ll check more with regression.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d920540",
   "metadata": {},
   "source": [
    "## Step 6: Doing Simple Regression\n",
    "book exercise 15a tells to do simple regression for each thing against `CRIM`. i tried this now to see which one important for crime!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d3bea50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simple Regression of CRIM on ZN:\n",
      "Coefficient: -0.0739, p-value: 0.0000\n",
      "ZN has a significant relationship with CRIM (p < 0.05)!\n",
      "\n",
      "Simple Regression of CRIM on INDUS:\n",
      "Coefficient: 0.5098, p-value: 0.0000\n",
      "INDUS has a significant relationship with CRIM (p < 0.05)!\n",
      "\n",
      "Simple Regression of CRIM on CHAS:\n",
      "Coefficient: -1.8928, p-value: 0.2094\n",
      "\n",
      "Simple Regression of CRIM on NOX:\n",
      "Coefficient: 31.2485, p-value: 0.0000\n",
      "NOX has a significant relationship with CRIM (p < 0.05)!\n",
      "\n",
      "Simple Regression of CRIM on RM:\n",
      "Coefficient: -2.6841, p-value: 0.0000\n",
      "RM has a significant relationship with CRIM (p < 0.05)!\n",
      "\n",
      "Simple Regression of CRIM on AGE:\n",
      "Coefficient: 0.1078, p-value: 0.0000\n",
      "AGE has a significant relationship with CRIM (p < 0.05)!\n",
      "\n",
      "Simple Regression of CRIM on DIS:\n",
      "Coefficient: -1.5509, p-value: 0.0000\n",
      "DIS has a significant relationship with CRIM (p < 0.05)!\n",
      "\n",
      "Simple Regression of CRIM on RAD:\n",
      "Coefficient: 0.6179, p-value: 0.0000\n",
      "RAD has a significant relationship with CRIM (p < 0.05)!\n",
      "\n",
      "Simple Regression of CRIM on TAX:\n",
      "Coefficient: 0.0297, p-value: 0.0000\n",
      "TAX has a significant relationship with CRIM (p < 0.05)!\n",
      "\n",
      "Simple Regression of CRIM on PTRATIO:\n",
      "Coefficient: 1.1520, p-value: 0.0000\n",
      "PTRATIO has a significant relationship with CRIM (p < 0.05)!\n",
      "\n",
      "Simple Regression of CRIM on B:\n",
      "Coefficient: -0.0363, p-value: 0.0000\n",
      "B has a significant relationship with CRIM (p < 0.05)!\n",
      "\n",
      "Simple Regression of CRIM on LSTAT:\n",
      "Coefficient: 0.5488, p-value: 0.0000\n",
      "LSTAT has a significant relationship with CRIM (p < 0.05)!\n",
      "\n",
      "Simple Regression of CRIM on MEDV:\n",
      "Coefficient: -0.3632, p-value: 0.0000\n",
      "MEDV has a significant relationship with CRIM (p < 0.05)!\n"
     ]
    }
   ],
   "source": [
    "# List of predictors (excluding CRIM)\n",
    "predictors = [col for col in data.columns if col != 'CRIM']\n",
    "\n",
    "# Dictionary to store coefficients\n",
    "simple_coeffs = {}\n",
    "\n",
    "# Do simple linear regression for each predictor\n",
    "for predictor in predictors:\n",
    "    X = data[[predictor]]\n",
    "    X = sm.add_constant(X)\n",
    "    y = data['CRIM']\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    coeff = model.params[predictor]\n",
    "    p_value = model.pvalues[predictor]\n",
    "    simple_coeffs[predictor] = coeff\n",
    "    print(f\"\\nSimple Regression of CRIM on {predictor}:\")\n",
    "    print(f\"Coefficient: {coeff:.4f}, p-value: {p_value:.4f}\")\n",
    "    if p_value < 0.05:\n",
    "        print(f\"{predictor} has a significant relationship with CRIM (p < 0.05)!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4362f19",
   "metadata": {},
   "source": [
    "## Step 7: Making Big OLS Model\n",
    "now i made ols model with all feature to predict `CRIM`, like exercise 15b say. i want know which feature is important. lets see what i get!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "21301f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS Regression Results:\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   CRIM   R-squared:                       0.454\n",
      "Model:                            OLS   Adj. R-squared:                  0.440\n",
      "Method:                 Least Squares   F-statistic:                     31.47\n",
      "Date:                Tue, 20 May 2025   Prob (F-statistic):           1.57e-56\n",
      "Time:                        15:33:18   Log-Likelihood:                -1653.3\n",
      "No. Observations:                 506   AIC:                             3335.\n",
      "Df Residuals:                     492   BIC:                             3394.\n",
      "Df Model:                          13                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         17.0332      7.235      2.354      0.019       2.818      31.248\n",
      "ZN             0.0449      0.019      2.394      0.017       0.008       0.082\n",
      "INDUS         -0.0639      0.083     -0.766      0.444      -0.228       0.100\n",
      "CHAS          -0.7491      1.180     -0.635      0.526      -3.068       1.570\n",
      "NOX          -10.3135      5.276     -1.955      0.051     -20.679       0.052\n",
      "RM             0.4301      0.613      0.702      0.483      -0.774       1.634\n",
      "AGE            0.0015      0.018      0.081      0.935      -0.034       0.037\n",
      "DIS           -0.9872      0.282     -3.503      0.001      -1.541      -0.433\n",
      "RAD            0.5882      0.088      6.680      0.000       0.415       0.761\n",
      "TAX           -0.0038      0.005     -0.733      0.464      -0.014       0.006\n",
      "PTRATIO       -0.2711      0.186     -1.454      0.147      -0.637       0.095\n",
      "B             -0.0075      0.004     -2.052      0.041      -0.015      -0.000\n",
      "LSTAT          0.1262      0.076      1.667      0.096      -0.023       0.275\n",
      "MEDV          -0.1989      0.061     -3.287      0.001      -0.318      -0.080\n",
      "==============================================================================\n",
      "Omnibus:                      666.613   Durbin-Watson:                   1.519\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            84887.625\n",
      "Skew:                           6.617   Prob(JB):                         0.00\n",
      "Kurtosis:                      65.058   Cond. No.                     1.58e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.58e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for OLS\n",
    "X = data.drop('CRIM', axis=1)\n",
    "y = data['CRIM']\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the OLS model\n",
    "model = sm.OLS(y, X).fit()\n",
    "print(\"OLS Regression Results:\")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab05fa7",
   "metadata": {},
   "source": [
    "## Step 8: Checking Non-Linear Thing\n",
    "exercise 15d tells us to check if non-linear thing there by adding X^2 and X^3. i not understand fully, but i try with `LSTAT` because scatter plot show it important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f74d5d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS with Polynomial Terms (LSTAT, LSTAT^2, LSTAT^3):\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   CRIM   R-squared:                       0.218\n",
      "Model:                            OLS   Adj. R-squared:                  0.213\n",
      "Method:                 Least Squares   F-statistic:                     46.63\n",
      "Date:                Tue, 20 May 2025   Prob (F-statistic):           1.35e-26\n",
      "Time:                        15:33:18   Log-Likelihood:                -1744.2\n",
      "No. Observations:                 506   AIC:                             3496.\n",
      "Df Residuals:                     502   BIC:                             3513.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.2010      2.029      0.592      0.554      -2.785       5.187\n",
      "LSTAT         -0.4491      0.465     -0.966      0.335      -1.362       0.464\n",
      "LSTAT2         0.0558      0.030      1.852      0.065      -0.003       0.115\n",
      "LSTAT3        -0.0009      0.001     -1.517      0.130      -0.002       0.000\n",
      "==============================================================================\n",
      "Omnibus:                      607.734   Durbin-Watson:                   1.239\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            53621.219\n",
      "Skew:                           5.726   Prob(JB):                         0.00\n",
      "Kurtosis:                      52.114   Cond. No.                     5.20e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 5.2e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "If the p-values for LSTAT2 or LSTAT3 are small, there’s a non-linear relationship!\n"
     ]
    }
   ],
   "source": [
    "# Add polynomial terms for LSTAT\n",
    "data['LSTAT2'] = data['LSTAT'] ** 2\n",
    "data['LSTAT3'] = data['LSTAT'] ** 3\n",
    "\n",
    "# Fit OLS with LSTAT, LSTAT^2, and LSTAT^3\n",
    "X_poly = data[['LSTAT', 'LSTAT2', 'LSTAT3']]\n",
    "X_poly = sm.add_constant(X_poly)\n",
    "y = data['CRIM']\n",
    "poly_model = sm.OLS(y, X_poly).fit()\n",
    "print(\"OLS with Polynomial Terms (LSTAT, LSTAT^2, LSTAT^3):\")\n",
    "print(poly_model.summary())\n",
    "print(\"\\nIf the p-values for LSTAT2 or LSTAT3 are small, there’s a non-linear relationship!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d477402",
   "metadata": {},
   "source": [
    "## Step 9: Comparing Coefficient\n",
    "exercise 15c says to make plots to compare coefficient from simple regression (step 6) and big regression (step 7)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b5c5227c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient comparison plot saved! If points are far from the red line, the coefficients are very different.\n"
     ]
    }
   ],
   "source": [
    "# Get coefficients from multiple regression\n",
    "multi_coeffs = model.params[1:]  # Exclude the constant\n",
    "\n",
    "# Prepare data for plotting\n",
    "coeff_data = pd.DataFrame({\n",
    "    'Simple': [simple_coeffs[p] for p in predictors],\n",
    "    'Multiple': [multi_coeffs[p] for p in predictors]\n",
    "}, index=predictors)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(coeff_data['Simple'], coeff_data['Multiple'], color='purple')\n",
    "for i, predictor in enumerate(predictors):\n",
    "    plt.annotate(predictor, (coeff_data['Simple'][i], coeff_data['Multiple'][i]))\n",
    "plt.plot([-0.5, 1.5], [-0.5, 1.5], 'r--')  # Line of equality\n",
    "plt.title('Simple vs Multiple Regression Coefficients')\n",
    "plt.xlabel('Simple Regression Coefficient')\n",
    "plt.ylabel('Multiple Regression Coefficient')\n",
    "plt.savefig('figures/coeff_comparison.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Coefficient comparison plot saved! If points are far from the red line, the coefficients are very different.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40b5a67",
   "metadata": {},
   "source": [
    "## Step 10: Doing Diagnostic Plot\n",
    "book contains diagnostic plot like residuals and fitted value. i made some to check my model is ok or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8072f7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diagnostic plots saved! I’ll check if residuals have patterns or if they’re not normal.\n"
     ]
    }
   ],
   "source": [
    "# Residuals vs Fitted\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(model.fittedvalues, model.resid, color='blue', alpha=0.5)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.title('Residuals vs Fitted Values')\n",
    "plt.xlabel('Fitted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.savefig('figures/residuals_vs_fitted.png')\n",
    "plt.close()\n",
    "\n",
    "# Q-Q Plot for Normality\n",
    "plt.figure(figsize=(8, 6))\n",
    "stats.probplot(model.resid, dist=\"norm\", plot=plt)\n",
    "plt.title('Q-Q Plot of Residuals')\n",
    "plt.savefig('figures/qq_plot.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Diagnostic plots saved! I’ll check if residuals have patterns or if they’re not normal.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7a92f7",
   "metadata": {},
   "source": [
    "## Step 11: Seeing If Model Good\n",
    "I saw R-squared in summary. Now i made a plot to check if predicted crime match is real crime or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "626c8fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual vs predicted plot saved! Most dots should be near the line if the model is good.\n"
     ]
    }
   ],
   "source": [
    "# Plot actual vs predicted crime rates\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y, model.predict(X), color='purple', alpha=0.5)\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2)\n",
    "plt.title('Actual vs Predicted Crime Rates')\n",
    "plt.xlabel('Actual Crime Rate (CRIM)')\n",
    "plt.ylabel('Predicted Crime Rate (CRIM)')\n",
    "plt.savefig('figures/actual_vs_predicted.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Actual vs predicted plot saved! Most dots should be near the line if the model is good.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a128904",
   "metadata": {},
   "source": [
    "## Step 12: Thinking About Problem in Data\n",
    "I read this dataset have some issue. I wrote about it to show that i think about this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f032f89",
   "metadata": {},
   "source": [
    "Boston dataset have column `B` which tells about black people in area. if i use this in model, it can make bias and treat race bad way, which is not fair. Also `LSTAT` (lower status people) mix economic thing with crime, i think its not correct. For learning its ok, but it should'nt be used for real decision because it can be unfair."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad7b3fd",
   "metadata": {},
   "source": [
    "## Step 13: Finishing My Task\n",
    "I finished my task now. I learned a lot while doing this, here is what i found:\n",
    "\n",
    "- **What I Learn**: heatmap show `LSTAT` and `MEDV` connect strong with `CRIM`. in simple regression, some feature important (p < 0.05), i saw in step 6.\n",
    "- **Model Result**: my ols model with all feature have R-squared [check summary in step 7], so it explains that much crime rate change.\n",
    "- **Non-Linear Thing**: polynomial model with `LSTAT` show [check p-values for LSTAT2, LSTAT3 in step 8]. if p-value small, non-linear there.\n",
    "- **Diagnostic**: i need check residuals plot and Q-Q plot to see if pattern or residuals not normal.\n",
    "- **Data Problem**: dataset have issue, like `B` column for race make bias. its ok for study, but not real use.\n",
    "- **How to Make Better**: maybe i remove feature with high p-value or try cross-validation to improve model.\n",
    "\n",
    "i saved all plot in `figures/` folder. i hope i did my work correctly! plz tell if i need change something ok! :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stats_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
